#!/usr/bin/env python3

# Name: compare_lca_queries.py
# Description: This is a python script is used by experiment 10 to 
#              compare the LCA results from using pfp_doc and the 
#              results from r-index
# Date: September 8th, 2022

import os
import argparse
import math
import csv
import pysam

def extract_list_of_seq_names(file_name):
    """
    Input: file_name - path to a sequence file
    Output: list - sequence header names
    """
    seq_names = []
    with open(file_name, "r") as seq_fd:
        for line in seq_fd:
            if '>' in line:
                seq_names.append(line.split()[0])
    return seq_names

def generate_seq_name_to_doc_dict(file_name):
    """
    Input: file_name - path to filelist for all document files
    Output: dictionary - a dictionary that maps names to document ids
    """
    seq_names_to_doc = {}
    with open(file_name, "r") as in_fd:
        for line in in_fd:
            curr_seq_headers = extract_list_of_seq_names(line.split()[0])
            curr_doc_id = int(line.split()[1]) - 1

            for seq_name in curr_seq_headers:
                # use substring here to avoid '>' at beginning
                seq_names_to_doc[seq_name[1:]] = curr_doc_id
    return seq_names_to_doc

def convert_reads_to_listings_for_rindex(sam_file, seq_to_doc):
    """
    Input: sam_file - path to sam file generated by r-index
           seq_to_doc - dictionary of sequence names to document number
    Output: dictionary - maps read names to document listings
    """
    read_to_doc_listing = {}
    curr_sam = pysam.AlignmentFile(sam_file, "r")

    for read in curr_sam.fetch():
        curr_aln_doc = seq_to_doc[read.reference_name]
        if read.query_name not in read_to_doc_listing:
            read_to_doc_listing[read.query_name] = [curr_aln_doc]
        else:
            read_to_doc_listing[read.query_name].append(curr_aln_doc)
    return read_to_doc_listing

def sort_and_filter_doc_listing_dict(reads_to_doc):
    """
    Input: reads_to_doc - dictionary of reads names to document listings
    Output: reads_to_doc_sort - dictionary of read names to document listings sorted numerically 
            reads_to_doc_lca - dictionary of read names to smallest, largest doc number from profile
    """
    reads_to_doc_lca = {}
    for key in reads_to_doc:
        reads_to_doc[key].sort()    
        reads_to_doc_lca[key] = [reads_to_doc[key][0], reads_to_doc[key][-1]]  
    return reads_to_doc, reads_to_doc_lca

def extract_docprofiles_listings(listings):
    """
    Input: listings - path to listing file generated from pfp_doc
    Output: read_to_doc - dictionary mapping read to smallest, largest doc number 
    """
    read_to_doc = {}
    with open(listings, "r") as listing_fd:
        curr_read_name = ""
        for line in listing_fd:
            if '>' in line:
                curr_read_name = line[1:].strip()
            elif '>' not in line:
                curr_list = line.split("{")[1].split(",")
                if len(curr_list) != 2:
                    print(curr_read_name)
                assert len(curr_list) == 2

                curr_list[1] = curr_list[1].split('}')[0]
                curr_list_int = [int(x) for x in curr_list]

                read_to_doc[curr_read_name] = curr_list_int
    return read_to_doc

def main(args):
    """ Main method """
    # Step 1: Load references and determine which sequence names are in which documents
    seq_names_to_doc = generate_seq_name_to_doc_dict(args.filelist)

    # Step 2: Convert r-index SAM file to a document listing for each read
    reads_to_doc_rindex = convert_reads_to_listings_for_rindex(args.sam_file, seq_names_to_doc)

    # Step 3: Convert dictionary to sort each document listings and the smallest, largest doc
    reads_to_doc_rindex_sort, reads_to_rindex_lca = sort_and_filter_doc_listing_dict(reads_to_doc_rindex)

    # Step 4: Extract the LCA doc listings from doc profiles
    reads_to_doc_docprofiles = extract_docprofiles_listings(args.listings)

    # Step 5: Compare the results from doc array and r-index
    with open(args.output, "w") as out_fd:
        assert len(reads_to_rindex_lca) == len(reads_to_doc_docprofiles)
        num_reads = len(reads_to_rindex_lca)
        num_matching_listings = 0

        for key in reads_to_rindex_lca:
            if reads_to_rindex_lca[key] == reads_to_doc_docprofiles[key]:
                num_matching_listings += 1
            else:
                out_fd.write(f"read_name: {key}, r-index: {reads_to_rindex_lca[key]}, doc_array: {reads_to_doc_docprofiles[key]}\n")

        out_fd.write(f"\n\nOut of {num_reads}, there are {num_matching_listings} with matching listings.\n") 

def parse_arguments():
    """ Defines the command-line argument parser, and return arguments """
    parser = argparse.ArgumentParser(description="This script is for experiment 10, comparing LCA queries.")
    parser.add_argument("-f", "--filelist", dest="filelist", required=True, type=str)
    parser.add_argument("-s", "--sam", dest="sam_file", required=True, type=str)
    parser.add_argument("-l", "--listings", dest="listings", required=True, type=str)
    parser.add_argument("-o", "--output", dest="output", required=True, type=str)
    args = parser.parse_args()
    return args

def check_arguments(args):
    """ Checks for invalid arguments """
    if not os.path.isfile(args.filelist):
        print("Error: path to filelist is not valid")
        exit(1)
    if not os.path.isfile(args.sam_file):
        print("Error: path to sam file is not valid")
        exit(1)
    if not os.path.isfile(args.listings):
        print("Error: path to listings is not valid")
        exit(1)

if __name__ == "__main__":
    args = parse_arguments()
    check_arguments(args)
    main(args)